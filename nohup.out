/mnt/groupprofxghan/yiqun/workspace/PU-Net_pytorch/dataset.py:16: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.
  h5_file = h5py.File(h5_file_path)
/mnt/groupprofxghan/yiqun/workspace/PU-Net_pytorch/dataset.py:16: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.
  h5_file = h5py.File(h5_file_path)
 -- epoch 0, loss 0.025046705290675163.
 -- epoch 1, loss 0.014614775069057942.
 -- epoch 2, loss 0.012519746363162994.
 -- epoch 3, loss 0.011516745783388615.
 -- epoch 4, loss 0.010964821405708789.
 -- epoch 5, loss 0.010662730850279332.
 -- epoch 6, loss 0.010627379551529884.
 -- epoch 7, loss 0.010584782145917416.
 -- epoch 8, loss 0.010638500958681107.
 -- epoch 9, loss 0.010641395568847656.
 -- epoch 10, loss 0.010628837406635285.
 -- epoch 11, loss 0.010656927414238453.
 -- epoch 12, loss 0.010753304712474347.
 -- epoch 13, loss 0.010731644369661808.
 -- epoch 14, loss 0.010435069777071477.
 -- epoch 15, loss 0.009573143772780896.
 -- epoch 16, loss 0.009435417957603932.
 -- epoch 17, loss 0.009235574565827846.
 -- epoch 18, loss 0.009001862585544586.
 -- epoch 19, loss 0.008978094227612018.
 -- epoch 20, loss 0.008963401082903147.
 -- epoch 21, loss 0.008806920643895865.
 -- epoch 22, loss 0.008789935819804669.
 -- epoch 23, loss 0.008672259852290153.
 -- epoch 24, loss 0.008792255319654942.
 -- epoch 25, loss 0.008704093873500823.
 -- epoch 26, loss 0.008603592090308667.
 -- epoch 27, loss 0.008594006773084402.
 -- epoch 28, loss 0.008531399827450515.
 -- epoch 29, loss 0.008571016397327184.
 -- epoch 30, loss 0.00854357647523284.
 -- epoch 31, loss 0.008560756288468838.
 -- epoch 32, loss 0.008554330877959728.
 -- epoch 33, loss 0.00845398611947894.
 -- epoch 34, loss 0.008505692575126886.
 -- epoch 35, loss 0.008505203291773795.
 -- epoch 36, loss 0.00846337440609932.
 -- epoch 37, loss 0.008433861907571553.
 -- epoch 38, loss 0.008542241103947162.
 -- epoch 39, loss 0.008390454616397619.
 -- epoch 40, loss 0.008421233534812927.
 -- epoch 41, loss 0.008440853625535965.
 -- epoch 42, loss 0.008382890287786722.
 -- epoch 43, loss 0.00838433101028204.
 -- epoch 44, loss 0.008420428480952978.
 -- epoch 45, loss 0.00830865740403533.
 -- epoch 46, loss 0.00838081556558609.
 -- epoch 47, loss 0.00829596172645688.
 -- epoch 48, loss 0.008258158918470144.
 -- epoch 49, loss 0.008314682308584452.
 -- epoch 50, loss 0.008255624759942293.
 -- epoch 51, loss 0.008336890399456023.
 -- epoch 52, loss 0.008232515059411525.
 -- epoch 53, loss 0.008251725405454635.
 -- epoch 54, loss 0.00834233107790351.
 -- epoch 55, loss 0.008276162136346101.
 -- epoch 56, loss 0.008219910103827714.
 -- epoch 57, loss 0.008256692465394736.
 -- epoch 58, loss 0.008195487134158611.
 -- epoch 59, loss 0.008296056300401687.
 -- epoch 60, loss 0.008247693274170161.
 -- epoch 61, loss 0.00823085342347622.
 -- epoch 62, loss 0.008333975069224835.
 -- epoch 63, loss 0.008282021161168813.
 -- epoch 64, loss 0.008252756625413894.
 -- epoch 65, loss 0.008279416140168906.
 -- epoch 66, loss 0.00822267711535096.
 -- epoch 67, loss 0.008252172358334064.
 -- epoch 68, loss 0.00825146309658885.
 -- epoch 69, loss 0.00821833085268736.
 -- epoch 70, loss 0.00829621747136116.
 -- epoch 71, loss 0.008209390796720981.
 -- epoch 72, loss 0.008255709037184715.
 -- epoch 73, loss 0.008202601626515389.
 -- epoch 74, loss 0.00824431512132287.
 -- epoch 75, loss 0.008286986500024796.
 -- epoch 76, loss 0.00816770338267088.
 -- epoch 77, loss 0.008230261258780956.
 -- epoch 78, loss 0.008229543063789606.
 -- epoch 79, loss 0.008232271045446396.
 -- epoch 80, loss 0.00829493486881256.
 -- epoch 81, loss 0.008195044469088315.
 -- epoch 82, loss 0.008249074395745992.
 -- epoch 83, loss 0.008360937669873237.
 -- epoch 84, loss 0.00828226101025939.
 -- epoch 85, loss 0.008205019488930702.
 -- epoch 86, loss 0.008215550806373357.
 -- epoch 87, loss 0.008257149159908295.
 -- epoch 88, loss 0.00824549837037921.
 -- epoch 89, loss 0.008153226785361766.
 -- epoch 90, loss 0.00828397537395358.
 -- epoch 91, loss 0.008233547788113355.
 -- epoch 92, loss 0.008223704796284438.
 -- epoch 93, loss 0.008256223138421774.
 -- epoch 94, loss 0.008248044587671756.
 -- epoch 95, loss 0.008194065116345883.
 -- epoch 96, loss 0.008226228423416615.
 -- epoch 97, loss 0.008220960717648268.
 -- epoch 98, loss 0.008230113465338945.
 -- epoch 99, loss 0.008181332346051931.
